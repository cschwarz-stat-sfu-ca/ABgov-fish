---
title: "Power Analysis for Quirk Creek"
author: "Carl Schwarz"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output:
  html_document:
    number_sections: yes
    toc: yes
  pdf_document:
    number_sections: yes
    toc: yes
  word_document:
    fig_caption: yes
    reference_docx: TrendPowerReport-STYLE.docx
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Estimate the power to detect a 20, 50, 100, 200 and 300% increase in the abundance over 5 years
# This data has information on the within-year variation, but no information on process error.

# As usually, convert the estimates of variablity to the log-scale to answer the above questions.

library(ggplot2)
library(lme4)
library(lmerTest)
library(pander)
library(plyr)
library(readxl)
library(reshape2)

source("functions.R")

# Set Figure and Table number variables. DO NOT CHANGE these except at your peril
# Get the figure or table number before the first time you reference it.
.FIGNUM <- 0
.TABNUM <- 0


# Get the raw data and do editing. This won't appear in the report, but gives you 
# an audit trail of what you did to the raw data before creating the rest of the
# template

# Enter the workbook name and worksheet name containing the FWIS output
# If JAVA isn't working, enter the name of the csv file.

workbookName = 'Data/Quirk Creek.xls'
sheetName    = 'F&W'
csvfilename  = file.path("Data","Quirk Creek.csv")

# CHoose one of the following code fragments, depending if JAVA is working or not.
#  If xlxs package is working
# Check that  FWIS files exists
#if(!file.exists(workbookName))stop(paste("File ",workbookName,' not found '))

# read the sheet from the workbook
#cpue <- read.FWIS.workbook(
#        workbookName  =workbookName,
#        sheetName     =sheetName,
#        target.species=target.species)

# Read the csv file
# Check that  FWIS files exists
if(!file.exists(csvfilename))stop(paste("File ",csvfile,' not found '))

cpue <- read.FWIS.workbook.csv(
        csvfilename)


# check that things seem to be ok so far
head(cpue)

# what years are present in this workbooks?
xtabs(~Year, data=cpue, exclude=NULL, na.action=na.pass)

# what species are present in this workbook
xtabs(~Species.Code, data=cpue, exclude=NULL, na.action=na.pass)

# After reading in the data, you should check  basic statistics such as the years
# measurements are taken, the Location names are spelled consistently, etc
xtabs(~Activity.Date+Inventory.Survey.ID, data=cpue, exclude=NULL, na.action=na.pass)
unique(cpue[,c("Activity.Date","Inventory.Survey.ID")])


xtabs(~LocationTTM+Year,      data=cpue , exclude=NULL, na.action=na.pass)
# are there any dates that are invalid
cpue[ is.na(cpue$Year),]

xtabs(~Species.Code + Year,  data=cpue , exclude=NULL, na.action=na.pass)
cpue[ is.na(cpue$Species.Code) | cpue$Species.Code=="",]
# remove records with blank species codes
dim(cpue)
cpue <- cpue[ !(is.na(cpue$Species.Code) | cpue$Species.Code==""),]
dim(cpue)
xtabs(~Species.Code + Year,  data=cpue , exclude=NULL, na.action=na.pass)


xtabs(~Survey.Type + Year,     data=cpue , exclude=NULL, na.action=na.pass)
# Remove all non-electrofishing survey types
dim(cpue)
cpue <- cpue[ cpue$Survey.Type %in% c("Electrofishing"),]
dim(cpue)
xtabs(~Survey.Type + Year,     data=cpue , exclude=NULL, na.action=na.pass)


# Check the equipment type field
xtabs(~Equipment.Type + Year,    data=cpue , exclude=NULL, na.action=na.pass)
xtabs(~Equipment.Type + Survey.Type, data=cpue, exclude=NULL, na.action=na.pass)

# check the Distance and time fields
xtabs(~Distance..m., data=cpue, exclude=NULL, na.action=na.pass)
xtabs(~LocationTTM+Distance..m., data=cpue, exclude=NULL, na.action=na.pass)

# impute a distance field
cpue$Distance..m.[ is.na(cpue$Distance..m.)] <- 100
xtabs(~Distance..m., data=cpue, exclude=NULL, na.action=na.pass)
xtabs(~LocationTTM+Distance..m., data=cpue, exclude=NULL, na.action=na.pass)

xtabs(~Inventory.Survey.ID+Distance..m., data=cpue, exclude=NULL, na.action=na.pass)

xtabs(~Time..s.,     data=cpue, exclude=NULL, na.action=na.pass)# remove data where no distance or time


# check the counts by species
xtabs(~Species.Code+Total.Count.of.Species.by.SurveyID, data=cpue, exclude=NULL, na.action=na.pass)

# Compute the catch summary
# We first extract for each Inventory.Survey.ID, one record per species
catch.summary <- plyr::ddply(cpue, c("WatershedName","Species.Code","Inventory.Survey.ID","Year","LocationTTM"), plyr::summarize,
                            Distance..m. = mean(Distance..m., na.rm=TRUE),
                            Count        = mean(Total.Count.of.Species.by.SurveyID))
# Now we need to expand for each Inventory.Survey.ID the full set of species 
# and impute 0 values for species not seen for this inventory (i.e 0 catch of this species)
which.species <- unique(catch.summary$Species.Code)
all.catch <- plyr::ddply(catch.summary, "Inventory.Survey.ID", function(x, species.list){
     all.species <- expand.grid(Inventory.Survey.ID=x$Inventory.Survey.ID[1],
                                Distance..m.       =x$Distance..m.[1],
                                Year               =x$Year[1],
                                LocationTTM        =x$LocationTTM[1],
                                WatershedName      =x$WatershedName[1],
                                Species.Code       =species.list,
                                stringsAsFactors=FALSE)
     all.species
}, species.list=which.species)
catch.summary <- merge(catch.summary, all.catch, all=TRUE)
catch.summary$Count[ is.na(catch.summary$Count)] <- 0

catch.summary <- plyr::ddply(catch.summary, c("WatershedName","Species.Code","Year","LocationTTM"), plyr::summarize,
                             Distance..m. = sum(Distance..m., na.rm=TRUE),
                             Count        = sum(Count,        na.rm=TRUE),
                             CPUE.300m    = Count / Distance..m. * 300)

xtabs(~Species.Code+Year, data=catch.summary, exclude=NULL, na.action=na.pass)
xtabs(~LocationTTM+Year, data=catch.summary, exclude=NULL, na.action=na.pass)
xtabs(~LocationTTM+Species.Code+Year, data=catch.summary[catch.summary$Year==2015,], exclude=NULL, na.action=na.pass)


target.species <- 'ALL'
#target.species <- c("BKTR","BLTR","MNWH") # or you can select which species to include

if(target.species != 'ALL'){
   catch.summary <- catch.summary[ catch.summary$Species.Code %in% target.species,]
}

```

# Introduction.
```{r echo=FALSE, include=FALSE}
summary.TABNUM <- getTABNUM()
```
This is a power analysis on the CPUE sampling program for the `r catch.summary$WatershedName[1]` watershed. A summary
of the number of locations sampled by year is found in Table `r summary.TABNUM`.
```{r LocationYear, echo=FALSE, results='asis'}
summary.loc <- plyr::ddply(catch.summary, c("Year"), plyr::summarize,
                       Locations = length(unique(LocationTTM)))
summary.fish <- plyr::ddply(catch.summary, c("Year","Species.Code"), plyr::summarize,
                       nFish= sum(Count))
summary.fish.wide <- reshape2::dcast(summary.fish, Year~Species.Code,  value.var='nFish')
summary.fish.wide <- merge(summary.loc, summary.fish.wide)

pandoc.table(summary.fish.wide,
             caption=paste("Table ", summary.TABNUM, ". Summary of locations and fish captured by year", sep=""),
             justify=rep("right", ncol(summary.fish.wide)))

```
```{r prelim.fignum, echo=FALSE, include=FALSE}
prelim.FIGNUM <- getFIGNUM()
```

A preliminary plot of the CPUE over time for each of the species is found in Figure `r prelim.FIGNUM`.

```{r prelim.plot, echo=FALSE, fig.height=6, fig.width=6, dpi=300}
# Preliminary plot of the CPUE

prelim <- ggplot(data=catch.summary, aes(x=Year, y=CPUE.300m))+
   ggtitle(paste('Figure ', prelim.FIGNUM,". CPUE for ",catch.summary$WatershedName[1]))+
   theme(plot.title = element_text(size = 8))+  # change text size for title
   geom_point( position=position_jitter(w=.2))+
   geom_line(aes(group=LocationTTM))+
   geom_smooth(method="lm", se=FALSE)+
   facet_wrap(~Species.Code, scales="free_y", ncol=2)+
   ylab("CPUE (fish/ 300 m)")+
   xlab("Year\nSame locations joined over time")
prelim

prelim.log <- ggplot(data=catch.summary, aes(x=Year, y=log(CPUE.300m+.01)))+
   ggtitle(paste('Figure ', prelim.FIGNUM,". CPUE for ",catch.summary$WatershedName[1]))+
   theme(plot.title = element_text(size = 8))+  # change text size for title
   geom_point( position=position_jitter(w=.2))+
   geom_line(aes(group=LocationTTM))+
   geom_smooth(method="lm", se=FALSE)+
   facet_wrap(~Species.Code, scales="free_y", ncol=2)+
   ylab("log(CPUE (fish/ 300 m) + .01)")+
   xlab("Year\nSame locations joined over time")
#prelim.log  # uncomment if you want the plot on the log scale
```

# Variance components
```{r varcomp.tabnum, echo=FALSE}
varcomp.tabnum <- getTABNUM()
```

The variance components were estimated after fitting a linear mixed model to the CPUE on the logarithmic scale.
A summary of the estimated variance components is found in Table `r varcomp.tabnum`.

```{r varcomp, echo=FALSE, results='asis', message=FALSE, warning=FALSE}

# fit the model to the log to get the sampling and process error relative to the mean
# we need to add some variable names
catch.summary$Watershed <- catch.summary$WatershedName
catch.summary$value     <- catch.summary$CPUE.300m
catch.summary$Type      <- 'Electofishing'
catch.summary$Measure   <- 'CPUE 300m'
catch.summary$Location..<- catch.summary$LocationTTM


vc <-  plyr::ddply(catch.summary, c("WatershedName","Species.Code","Measure","Type"), estimate.var.comp)

table <- vc[,c("Species.Code","SD.sampling","SD.process")]
table$SD.sampling <- round(table$SD.sampling,2)
table$SD.process  <- round(table$SD.process ,2)
colnames(table) <- c("Species","Sampling\nSD","Process\nSD")

pandoc.table(table,
             caption=paste("Table ", varcomp.tabnum, ". Estimated variance components (log scale)"),
             justify='lrr')

```

```{r   results='asis', echo=FALSE, eval=length(unique(catch.summary$Year))==1}
cat("It is not possible to distinguish between sampling and process standard deviations when there is only one ")
cat(" year of data, and so values were imputed.")
```
```{r   results='asis', echo=FALSE, eval=length(unique(catch.summary$Year))==2}
cat("Because there were only two years of data, it is not possible to fit a trend and so a constant mean was ")
cat(" assumed over the two years of data.")
```




```{r   echo=FALSE, results='asis'}
# you need to manually change SD.process if there is only 1 year of sampling
# or if they cannot be estimated.
# At the moment, I just delete then
if(any(is.na(vc$SD.sampling) | is.na(vc$SD.process))){
  cat("Some variance components could not be estimated and no power analysis is possible for those species.")
}
vc <- vc[ !(is.na(vc$SD.sampling) | is.na(vc$SD.process)),]
```

```{r computepower, echo=FALSE}
# now for power charts to detect 10%, 30%, 50%, 100%, 200%, 300% change over 5 years 
# by varying the number of sites at different levels of process error

power.res <- ddply(vc, c("WatershedName","Species.Code","Type","Measure"), estimate.power)

# The actual power values are available if you want to do furter analyses
# or plots but we will produce some standard plots
#head(power.res)
```
# Power analysis
```{r power.fignum, echo=FALSE}
power.fignum <- getFIGNUM()
```

A power analysis was conducted to detect a 10%, 30%, 50%, 100%, 200%, 300% change over 5 years
by varying the number of sites given the sampling and process error estimated above. Results
are summarized in Figure `r power.fignum` (one plot per species).
```{r compute.power, echo=FALSE}
power.res <- ddply(vc, c("WatershedName","Species.Code","Type","Measure"), estimate.power)

# You can make a table or stick with the standard plot below.

# make a plot for each species
plots.list <- plyr::dlply(power.res, "Species.Code", function(power){
   #browser()
   plotdata <- power
   plotdata$Years2 <- paste("Over ", plotdata$Year," Years",sep="")
   plotdata$PerChangeF <- factor(plotdata$PerChange)
   power.plot <- ggplot2::ggplot(data=plotdata, aes(x=sites.per.year, y=power.1sided.a, color=PerChangeF))+
      ggtitle(paste("Power to detect changes over time for \n", power$Watershed[1], " ",power$Species.Code[1],"  ",
                       power$Measure[1],"\n alpha=",power$alpha[1],
                    "; rProcess SD= ", format(round(power$Process.SD[1] ,2),nsmall=2), 
                    "; rSampling SD= ",format(round(power$Sampling.SD[1],2),nsmall=2), sep=""))+
      geom_line(aes(group=PerChangeF, linetype=PerChangeF))+
      ylab("Power")+ylim(0,1)+geom_hline(yintercept=0.80)+
      facet_wrap(~Years2, ncol=1, scales='fixed')+
      scale_color_discrete(name="Percent\nChange")+
      scale_linetype_discrete(name="Percent\nChange")
      xlab("Sites per year")
  power.plot
})
```

```{r makeplots, echo=FALSE, fig.height=6, fig.width=6, dpi=300}
# make the plots
l_ply(plots.list, function (x){ plot(x); cat("\n")})
```


# Summary
**Add text here summarizing the bleak results**





